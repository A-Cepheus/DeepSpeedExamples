{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = glob.glob('/blob/data/3dmodels/views_release/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (check)\n",
    "\n",
    "allL = []\n",
    "for x in check:\n",
    "    allL.append(x.split('/blob/data/3dmodels/views_release/')[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79886"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(allL, test_size=0.01, random_state=42)\n",
    "\n",
    "# Create a dictionary to store the train and test sets\n",
    "split_data = {\"train\": train_data, \"test\": test_data}\n",
    " \n",
    "# Save the split data to a JSON file\n",
    "with open(\"/vc_data/users/xwu/Model3d/LEAP/data_objaverse/split_info_test_1123.json\", \"w\") as json_file:\n",
    "    json.dump(split_data, json_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.activations import ACT2FN\n",
    "from transformers.modeling_outputs import (\n",
    "    BackboneOutput,\n",
    "    BaseModelOutput,\n",
    "    BaseModelOutputWithPooling,\n",
    "    ImageClassifierOutput,\n",
    ")\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from transformers.pytorch_utils import find_pruneable_heads_and_indices, prune_linear_layer\n",
    "from transformers.utils import (\n",
    "    add_code_sample_docstrings,\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    logging,\n",
    "    replace_return_docstrings,\n",
    ")\n",
    "from transformers.utils.backbone_utils import BackboneMixin\n",
    "from transformers.models.dinov2.configuration_dinov2 import Dinov2Config\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.third_party_transformer.modeling_dinov2_config import Dinov2Config\n",
    "from model.third_party_transformer.modeling_dinov2 import Dinov2Backbone\n",
    "config = Dinov2Config(768)#'facebook/dinov2-base'\n",
    "# config.hidden_size=768\n",
    "\n",
    "# print (config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5e18dfb4f0b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDinov2Backbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'facebook/dinov2-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2506\u001b[0m                 \u001b[0;31m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2507\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   2508\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2509\u001b[0m                     \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, endpoint, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                     \u001b[0m_check_disk_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1445\u001b[0;31m             http_get(\n\u001b[0m\u001b[1;32m   1446\u001b[0m                 \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m                 \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, timeout, max_retries, expected_size)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mdisplayed_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"(â€¦){displayed_name[-40:]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m     progress = tqdm(\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/huggingface_hub/utils/tqdm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mare_progress_bars_disabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"disable\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         self.container = self.status_printer(\n\u001b[0m\u001b[1;32m    232\u001b[0m             self.fp, total, self.desc, self.ncols)\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_here\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Prepare IPython progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;34m\"IProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "backbone = Dinov2Backbone.from_pretrained('facebook/dinov2-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch#num_frames=5,\n",
    "def create_mock_input(batch_size=1,  channels=3, height=256, width=256):\n",
    "    images = torch.randn(batch_size,  channels, height, width)\n",
    "    camera_intri = torch.randn(batch_size, 768)\n",
    "    sample = {'images': images, 'camera_intri': camera_intri}\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = create_mock_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['images'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dinov2Backbone(\n",
      "  (embeddings): Dinov2Embeddings(\n",
      "    (patch_embeddings): Dinov2PatchEmbeddings(\n",
      "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Dinov2Encoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): Dinov2Layer(\n",
      "        (attention): Dinov2Attention(\n",
      "          (attention): Dinov2SelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): Dinov2SelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (layer_scale1): Dinov2LayerScale()\n",
      "        (drop_path1): Identity()\n",
      "        (mlp): Dinov2MLP(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (activation): GELUActivation()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (layer_scale2): Dinov2LayerScale()\n",
      "        (drop_path2): Identity()\n",
      "        (norm1): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (norm2): LNPos(\n",
      "          (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (adaLN_modulation): Sequential(\n",
      "            (0): SiLU()\n",
      "            (1): Linear(in_features=768, out_features=1536, bias=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layernorm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = backbone(sample['images'], sample['camera_intri'], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check.feature_maps) #.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768, 16, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.feature_maps[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.feature_maps[0].view(check.feature_maps[0].size(),,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(check.feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=4, out_features=768, bias=False)\n",
       "  (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): GELU()\n",
       "  (3): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): GELU()\n",
       "  (6): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (7): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (8): GELU()\n",
       "  (9): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (10): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (11): GELU()\n",
       "  (12): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (13): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (14): GELU()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "nn.ModuleList([\n",
    "            nn.Linear(4, 768, bias=False),\\\n",
    "            nn.BatchNorm2d(768), \\\n",
    "            nn.GELU(),\\\n",
    "            nn.Linear(768, 768, bias=False),\\\n",
    "            nn.BatchNorm2d(768), \\\n",
    "            nn.GELU(),\\\n",
    "            nn.Linear(768, 768, bias=False),\\\n",
    "            nn.BatchNorm2d(768), \\\n",
    "            nn.GELU(),\\\n",
    "            nn.Linear(768, 768, bias=False),\\\n",
    "            nn.BatchNorm2d(768), \\\n",
    "            nn.GELU(),\\\n",
    "            nn.Linear(768, 768, bias=False),\\\n",
    "            nn.BatchNorm2d(768), \\\n",
    "            nn.GELU()])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
